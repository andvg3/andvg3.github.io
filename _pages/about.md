---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Greetings from An Dinh Vuong, an incoming PhD student at MBZUAI specializing in Computer Vision and Robotics. I will be working under the guidance of [Prof. Ian Reid](https://cs.adelaide.edu.au/~ianr/), and I previously had the privilege of being advised by [Dr. Anh Nguyen](https://cgi.csc.liv.ac.uk/~anguyen/). My research focuses on applying deep learning techniques to advance robotic applications.

# ğŸ”¥ News
- *2024.06*: &nbsp;ğŸ‰ğŸ‰ Our paper "HabiCrowd: A High Performance Simulator for Crowd-Aware Visual Navigation" has been accepted to IROS 2024.
- *2024.03*: &nbsp;ğŸ‰ğŸ‰ Our paper has been accepted to Neural Computing and Applications (IF=6.0).
- *2024.02*: &nbsp;ğŸ‰ğŸ‰ Our paper "Language-driven Grasp Detection" has been accepted to CVPR 2024.
- *2024.01*: &nbsp;ğŸ‰ğŸ‰ Our paper "Grasp-Anything: Large-scale Grasp Dataset from Foundation Models" has been accepted to ICRA 2024.

# ğŸ“ Publications

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IROS 2024</div><img src='images/habicrowd_2023.gif' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[HabiCrowd: A High Performance Simulator for Crowd-Aware Visual Navigation](https://arxiv.org/abs/2303.02401)

**An Vuong**, Toan Tien Nguyen, Minh Nhat VU, Baoru Huang, Dzung Nguyen, Huynh Thi Thanh Binh, Thieu Vo, Anh Nguyen

<!-- Place this tag where you want the button to render. -->
<a class="github-button"
   href="https://github.com/habicrowd/HabiCrowd"
   data-icon="octicon-star"
   data-size="large"
   data-show-count="true"
   aria-label="Star facebook/react on GitHub">Star</a>

[**Project page**](https://habicrowd.github.io/) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/cvpr_2024_.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Language-driven Grasp Detection](https://openaccess.thecvf.com/content/CVPR2024/html/Vuong_Language-driven_Grasp_Detection_CVPR_2024_paper.html)

**An Vuong**, Minh Nhat Vu, Baoru Huang, Nghia Nguyen, Hieu Le, Thieu Vo, Anh Nguyen

<!-- Place this tag where you want the button to render. -->
<a class="github-button"
   href="https://github.com/andvg3/LGD"
   data-icon="octicon-star"
   data-size="large"
   data-show-count="true"
   aria-label="Star facebook/react on GitHub">Star</a>

[**Project page**](https://airvlab.github.io/grasp-anything/) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICRA 2024</div><img src='images/grasp-anything_2023.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Grasp-Anything: Large-scale Grasp Dataset from Foundation Models](https://arxiv.org/abs/2309.09818)

**An Vuong**, Minh Nhat Vu, Hieu Le, Baoru Huang, Binh Huynh, Thieu Vo, Andreas Kugi, Anh Nguyen

<!-- Place this tag where you want the button to render. -->
<a class="github-button"
   href="https://github.com/andvg3/Grasp-Anything"
   data-icon="octicon-star"
   data-size="large"
   data-show-count="true"
   aria-label="Star facebook/react on GitHub">Star</a>

[**Project page**](https://airvlab.github.io/grasp-anything/) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2023</div><img src='images/LSDM_2023.jpeg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[ Language-driven Scene Synthesis using Multi-conditional Diffusion Model](https://arxiv.org/abs/2310.15948)

**An Vuong**, Minh Nhat Vu, Toan Tien Nguyen, Baoru Huang, Dzung Nguyen, Thieu Vo, Anh Nguyen

<!-- Place this tag where you want the button to render. -->
<a class="github-button"
   href="https://github.com/andvg3/LSDM"
   data-icon="octicon-star"
   data-size="large"
   data-show-count="true"
   aria-label="Star facebook/react on GitHub">Star</a>

[**Project page**](https://lang-scene-synth.github.io/) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IROS 2023</div><img src='images/iros_2023.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Open-Vocabulary Affordance Detection in 3D Point Clouds](https://arxiv.org/abs/2303.02401)

Toan Nguyen, Minh Nhat Vu, **An Vuong**, Dzung Nguyen, Thieu Vo, Ngan Le, Anh Nguyen

<!-- Place this tag where you want the button to render. -->
<a class="github-button"
   href="https://github.com/Fsoft-AIC/Open-Vocabulary-Affordance-Detection-in-3D-Point-Clouds"
   data-icon="octicon-star"
   data-size="large"
   data-show-count="true"
   aria-label="Star facebook/react on GitHub">Star</a>

[**Project page**](https://openad2023.github.io) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
[Best Overall and Best Student Paper award candidate]
</div>
</div>

# ğŸ– Honors and Awards
- *2023*: NeurIPS 2023 Scholar Award.

# ğŸ› ï¸ Services
- *2024.06*: Reviewer for the MFM-EAI Workshop at ICML 2024.

# ğŸ“– Educations
- *2018 - 2022*: Talented Class of the Computer Science Major at Hanoi University of Science and Technology.
- *2024 - present*: PhD Computer Vision at Mohamed bin Zayed University of Artificial Intelligence.

<!-- # ğŸ’» Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China. -->